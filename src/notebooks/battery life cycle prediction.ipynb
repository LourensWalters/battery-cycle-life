{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reproduce the findings reported in the original paper in this section. We use an ElasticNet model as well as Linear and Logistic Regression models. The paper implemented three models: \"Variance Model\", \"Discharge Model\" and \"Full Model\". The modelling approach was to feature engineer features that are linearly correlated to the response. This allows for the use of linear models e.g. Linear and Logistic regression.\n",
    "\n",
    "Our approach is to use first test the linear models, and then to use Deep Learning techniques to derive the features automatically, and then to compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We load features we have engineered according to the original paper from file. We used the code from the original paper to perform the feature engineering as a pre-processing step.\n",
    "The \"src/features/rebuilding_features.py\" script can be used for generating this dataset from the original data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"../../data/external/rebuild_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We split the data into test and training sets. We hold out a secondary testing set for independent testing. This is also done according to the methodology in the original paper."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many cells of each group of cells with second letter equal to 1,2 or 3\n",
    "numBat1 = len([i for i in list(df.cell_key) if i[1] == \"1\"])\n",
    "numBat2 = len([i for i in list(df.cell_key) if i[1] == \"2\"])\n",
    "numBat3 = len([i for i in list(df.cell_key) if i[1] == \"3\"])\n",
    "numBat = sum((numBat1,numBat2,numBat3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind = np.hstack((np.arange(0,(numBat1+numBat2),2),83))\n",
    "train_ind = np.arange(1,(numBat1+numBat2-1),2)\n",
    "secondary_test_ind = np.arange(numBat-numBat3,numBat);\n",
    "\n",
    "splits = [train_ind, test_ind, secondary_test_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now define feature and target columns for the baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "varmod_features = [\"variance_dQ_100_10\"]\n",
    "\n",
    "dismod_features = [\n",
    "    \"variance_dQ_100_10\",\n",
    "    \"minimum_dQ_100_10\",\n",
    "    \"skewness_dQ_100_10\",\n",
    "    \"kurtosis_dQ_100_10\",\n",
    "    \"discharge_capacity_2\",\n",
    "    \"diff_discharge_capacity_max_2\",\n",
    "]\n",
    "\n",
    "fullmod_features = [\n",
    "    \"minimum_dQ_100_10\",\n",
    "    \"variance_dQ_100_10\",\n",
    "    \"slope_lin_fit_2_100\",\n",
    "    \"intercept_lin_fit_2_100\",\n",
    "    \"discharge_capacity_2\",\n",
    "    \"mean_charge_time_2_6\",\n",
    "    \"minimum_IR_2_100\",\n",
    "    \"diff_IR_100_2\",\n",
    "]\n",
    "\n",
    "targetmod = [\"cycle_life\"]\n",
    "\n",
    "# Define feature and target columns for classifiers\n",
    "varclf_features = [\"variance_dQ_5_4\"]\n",
    "fullclf_features = [\n",
    "    \"minimum_dQ_5_4\",\n",
    "    \"variance_dQ_5_4\",\n",
    "    \"discharge_capacity_2\",\n",
    "    \"diff_IR_100_2\",\n",
    "]\n",
    "targetclf = [\"cycle_550_clf\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and response.\n",
    "def get_split(data, features, target, split):\n",
    "    X = data.iloc[split,:].loc[:,features]\n",
    "    y = data.iloc[split,:].loc[:,target]\n",
    "    return X, y\n",
    "\n",
    "# Record regression model performance.\n",
    "def eval_model(model, data, features, target, split):\n",
    "    rmse = list()\n",
    "    mpe = list()\n",
    "    rsq = list()\n",
    "    for split in splits:\n",
    "        X, y = get_split(data, features, target, split)\n",
    "        y = y.to_numpy()\n",
    "        pred = model.predict(X)\n",
    "        rmse.append(np.sqrt(mean_squared_error(pred, y)))\n",
    "        mpe.append(float(np.mean(np.abs((y - pred.reshape(-1,1))) / y * 100)))\n",
    "        rsq.append(model.score(X, y))\n",
    "    return rmse, mpe, rsq\n",
    "\n",
    "# Record classifier model performance.\n",
    "def eval_classifier(model, data, features, target, splits):\n",
    "    acc = list()    \n",
    "    for split in splits:\n",
    "        X, y = get_split(data, features, target, split)\n",
    "        pred = model.predict(X)\n",
    "        acc.append(accuracy_score(pred, y.values.ravel()))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net R^2: 0.778771357057023\n"
     ]
    }
   ],
   "source": [
    "# Train Elastic net\n",
    "x_train, y_train = get_split(df, varmod_features, targetmod, train_ind)\n",
    "\n",
    "alphas = np.linspace(0.0001,1,30)\n",
    "parameters = {\n",
    "    \"alpha\": alphas,\n",
    "    \"l1_ratio\": [0.001, 0.25, 0.5, 0.75, 1.]\n",
    "}\n",
    "enet = ElasticNet(random_state = 54)\n",
    "regr = GridSearchCV(enet, parameters, cv = 4)\n",
    "print(\"Elastic Net R^2: %s\" % regr.fit(x_train, y_train).score(x_train, y_train))\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "#print(\"Linear Regression: %s\" % lin_reg.fit(x_train, y_train).score(x_train, y_train))\n",
    "\n",
    "varmod_rmse, varmod_mpe, varmod_rsq = eval_model(regr, df, varmod_features, targetmod, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discharge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net R^2: 0.8760140929447078\n"
     ]
    }
   ],
   "source": [
    "# Train Elastic net\n",
    "x_train, y_train = get_split(df, dismod_features, targetmod, train_ind)\n",
    "\n",
    "alphas = np.linspace(0.0001, 1, 30)\n",
    "parameters = {\n",
    "    \"alpha\": alphas,\n",
    "    \"l1_ratio\": [0.001, 0.25, 0.5, 0.75, 1.]\n",
    "}\n",
    "enet = ElasticNet(random_state = 54, max_iter = 1000000)\n",
    "regr = GridSearchCV(enet, parameters, cv = 4)\n",
    "print(\"Elastic Net R^2: %s\" % regr.fit(x_train, y_train).score(x_train, y_train))\n",
    "\n",
    "dismod_rmse, dismod_mpe, dismod_rsq = eval_model(regr, df, dismod_features, targetmod, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net R^2: 0.9206964201191958\n"
     ]
    }
   ],
   "source": [
    "# Train Elastic net model\n",
    "x_train, y_train = get_split(df, fullmod_features, targetmod, train_ind)\n",
    "\n",
    "alphas = np.linspace(0.001, 1, 30)\n",
    "parameters = {\n",
    "    \"alpha\": alphas,\n",
    "    \"l1_ratio\": [0.001, 0.25, 0.5, 0.75, 1.]\n",
    "}\n",
    "enet = ElasticNet(random_state = 54, max_iter=1000000)\n",
    "regr = GridSearchCV(enet, parameters, cv = 4)\n",
    "print(\"Elastic Net R^2: %s\" % regr.fit(x_train, y_train).score(x_train, y_train))\n",
    "\n",
    "fullmod_rmse, fullmod_mpe, fullmod_rsq = eval_model(regr, df, fullmod_features, targetmod, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline models RMSE and MPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "             Model  RMSE - Train  RMSE - Primary test  RMSE - Secondary test  \\\n0   Variance model    151.983723           169.488406             184.342835   \n1  Discharge model    113.779118          8798.143718             260.284119   \n2       Full model     90.996104           131.012935             265.713679   \n\n   MPE - Train  MPE - Primary test  MPE - Secondary test  RSQ - Train  \\\n0    21.219173           21.783186             12.548031     0.778771   \n1    15.900996          234.036648             18.618743     0.876014   \n2    11.541854           19.138034             20.106816     0.920696   \n\n   RSQ - Primary test  RSQ - Secondary test  \n0            0.812269              0.581954  \n1         -504.869332              0.166575  \n2            0.887828              0.131441  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>RMSE - Train</th>\n      <th>RMSE - Primary test</th>\n      <th>RMSE - Secondary test</th>\n      <th>MPE - Train</th>\n      <th>MPE - Primary test</th>\n      <th>MPE - Secondary test</th>\n      <th>RSQ - Train</th>\n      <th>RSQ - Primary test</th>\n      <th>RSQ - Secondary test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Variance model</td>\n      <td>151.983723</td>\n      <td>169.488406</td>\n      <td>184.342835</td>\n      <td>21.219173</td>\n      <td>21.783186</td>\n      <td>12.548031</td>\n      <td>0.778771</td>\n      <td>0.812269</td>\n      <td>0.581954</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Discharge model</td>\n      <td>113.779118</td>\n      <td>8798.143718</td>\n      <td>260.284119</td>\n      <td>15.900996</td>\n      <td>234.036648</td>\n      <td>18.618743</td>\n      <td>0.876014</td>\n      <td>-504.869332</td>\n      <td>0.166575</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Full model</td>\n      <td>90.996104</td>\n      <td>131.012935</td>\n      <td>265.713679</td>\n      <td>11.541854</td>\n      <td>19.138034</td>\n      <td>20.106816</td>\n      <td>0.920696</td>\n      <td>0.887828</td>\n      <td>0.131441</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Model\":[\"Variance model\", \"Discharge model\", \"Full model\"],\n",
    "              \"RMSE - Train\": [varmod_rmse[0],dismod_rmse[0],fullmod_rmse[0]],\n",
    "              \"RMSE - Primary test\": [varmod_rmse[1],dismod_rmse[1],fullmod_rmse[1]],\n",
    "              \"RMSE - Secondary test\": [varmod_rmse[2],dismod_rmse[2],fullmod_rmse[2]],\n",
    "              \"MPE - Train\": [varmod_mpe[0],dismod_mpe[0],fullmod_mpe[0]],\n",
    "              \"MPE - Primary test\": [varmod_mpe[1],dismod_mpe[1],fullmod_mpe[1]],\n",
    "              \"MPE - Secondary test\": [varmod_mpe[2],dismod_mpe[2],fullmod_mpe[2]],\n",
    "              \"RSQ - Train\": [varmod_rsq[0],dismod_rsq[0],fullmod_rsq[0]],\n",
    "              \"RSQ - Primary test\": [varmod_rsq[1],dismod_rsq[1],fullmod_rsq[1]],\n",
    "              \"RSQ - Secondary test\": [varmod_rsq[2],dismod_rsq[2],fullmod_rsq[2]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The \"Discharge Model\" does not behave correctly. We need to investigate thus further.\n",
    "\n",
    "There is also too much variance between the primary and secondary test results. This is worrying. The models do not generalise well, and are possibly overfitted."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logreg: 0.8048780487804879\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "x_train, y_train = get_split(df, varclf_features, targetclf, train_ind)\n",
    "\n",
    "parameters = {\"C\": [0.01,0.1,0.5,0.75,1]}\n",
    "\n",
    "logreg = LogisticRegression(solver=\"liblinear\", random_state=54)\n",
    "clf = GridSearchCV(logreg, parameters, cv=4)\n",
    "print(\"Logreg: %s\" % clf.fit(x_train, y_train.values.ravel()).score(x_train, y_train.values.ravel()))\n",
    "\n",
    "varclf_acc = eval_classifier(clf, df, varclf_features, targetclf, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logreg: 0.6585365853658537\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "# Why is the full classifier worse than the variance classifier?\n",
    "x_train, y_train = get_split(df, fullclf_features, targetclf, train_ind)\n",
    "\n",
    "parameters = {\"C\": [0.01,0.1,0.5,0.75,1]}\n",
    "\n",
    "logreg = LogisticRegression(solver=\"liblinear\", random_state=54)\n",
    "clf = GridSearchCV(logreg, parameters, cv=4)\n",
    "print(\"Logreg: %s\" % clf.fit(x_train, y_train.values.ravel()).score(x_train, y_train.values.ravel()))\n",
    "\n",
    "fullclf_acc = eval_classifier(clf, df, fullclf_features, targetclf, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            Classifier  Acc - Train  Acc - Primary test  Acc - Secondary test\n0  Variance classifier     0.804878            0.767442                  0.95\n1      Full classifier     0.658537            0.627907                  0.60",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Classifier</th>\n      <th>Acc - Train</th>\n      <th>Acc - Primary test</th>\n      <th>Acc - Secondary test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Variance classifier</td>\n      <td>0.804878</td>\n      <td>0.767442</td>\n      <td>0.95</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Full classifier</td>\n      <td>0.658537</td>\n      <td>0.627907</td>\n      <td>0.60</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Classifier\":[\"Variance classifier\", \"Full classifier\"],\n",
    "              \"Acc - Train\": [varclf_acc[0],fullclf_acc[0]],\n",
    "              \"Acc - Primary test\": [varclf_acc[1],fullclf_acc[1]],\n",
    "              \"Acc - Secondary test\": [varclf_acc[2],fullclf_acc[2]]})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We obtained roughly similar results to the original paper. Given the small datasets we expected a lot of variation when using these models.\n",
    "\n",
    "We should spend some more time to see if we can iron some of these problems out (regularisation or reducing complexity of model), but at this point we however have enough information to see how Deep Learning algorithms might perform on this problem."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Learning model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We build a deep learning model by"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}