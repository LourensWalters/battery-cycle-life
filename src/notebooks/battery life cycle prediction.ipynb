{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We reproduce the findings reported in the original paper in this section. We use an ElasticNet model as well as Linear and Logistic Regression models. The paper implemented three models: \"Variance Model\", \"Discharge Model\" and \"Full Model\". The modelling approach was to feature engineer features that are linearly correlated to the response. This allows for the use of linear models e.g. Linear and Logistic regression.\n",
    "\n",
    "Our approach is to recreate and test the original linear models, and then to use Deep Learning techniques to derive the features automatically as an additional step and to compare results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "import src.constants as cst\n",
    "import src.features.rebuilding_features as rf\n",
    "import src.models.train_model as tm\n",
    "#from src.data.data_class import BatteryData\n",
    "#from src.data.load_data import DataLoader\n",
    "#from src.data.wrangle_data import DataWrangler\n",
    "\n",
    "#from rebuilding_features import load_batches_to_dict\n",
    "from src.visualization.helpers import print_dict_keys\n",
    "from os.path import join\n",
    "import src.models.data_pipeline as dp\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import style\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "#session = tf.compat.v1.Session(config=config)\n",
    "#tf.compat.v1.keras.backend.set_session(session)\n",
    "\n",
    "DATA_DIR = join(\"../../data/external\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print (physical_devices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data exploration"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We load the data used by the original paper. To ease analysis due to data size we start by loading one batch only. The original paper used 3 batches, one for training, one for testing and another for further testing. We start by analysing the training dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "36.50641441345215"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "psutil.virtual_memory().available * 100 / psutil.virtual_memory().total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "path1 = Path(\"../../data/external/batch1.pkl\")\n",
    "batch1 = pickle.load(open(path1, 'rb'))\n",
    "#batch2 = dict(itertools.islice(pickle.load(open(path1, 'rb')).items(), 4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "32.85844326019287"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory().available * 100 / psutil.virtual_memory().total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "22"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch2 = dict(itertools.islice(batch1.items(), 4))\n",
    "batch1 = \"\"\n",
    "del batch1\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "41.68801307678223"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory().available * 100 / psutil.virtual_memory().total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['b1c0', 'b1c1', 'b1c2', 'b1c3'])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch2.keys()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "35.27717590332031"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.virtual_memory().available * 100 / psutil.virtual_memory().total\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m batch_subset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(itertools\u001B[38;5;241m.\u001B[39mislice(\u001B[43mbatch1\u001B[49m\u001B[38;5;241m.\u001B[39mitems(), \u001B[38;5;241m4\u001B[39m))\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m batch1\n\u001B[1;32m      3\u001B[0m gc\u001B[38;5;241m.\u001B[39mcollect()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'batch1' is not defined"
     ]
    }
   ],
   "source": [
    "batch_subset = dict(itertools.islice(batch1.items(), 4))\n",
    "del batch1\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print_dict_keys(batch1[\"b1c0\"]['cycles'], max_depth=1)\n",
    "style.use('fivethirtyeight')\n",
    "sns.set_palette('Accent')\n",
    "palette = itertools.cycle(sns.color_palette('Accent'))\n",
    "\n",
    "n_rows, n_cols = (3,2)\n",
    "\n",
    "figure, axes = plt.subplots(nrows=n_rows, ncols=n_cols,figsize=(15, 20))\n",
    "figure.suptitle('\\nDistributions of Continuous Variables', fontsize=25)\n",
    "\n",
    "for index, column in enumerate(quantitative_cols):\n",
    "    i,j = (index // n_cols), (index % n_cols)\n",
    "    miss_perc=\"%.2f\"%(100*(1-(df_auto[column].dropna().shape[0])/df_auto.shape[0]))\n",
    "    collabel=column+\"\\n({}% is missing)\".format(miss_perc)\n",
    "    fig=sns.distplot(df_auto[column], label=collabel, norm_hist=True,\n",
    "    ax=axes[i,j], kde_kws={\"lw\":4}, color=next(palette))\n",
    "    fig=fig.legend(loc='best', fontsize=18)\n",
    "    axes[i,j].set_ylabel(\"Probability Density\",fontsize='medium')\n",
    "    axes[i,j].set_xlabel(None)\n",
    "figure.delaxes(axes[2,1])\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start by considering the response variable i.e. \"cycle life\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in batch1.keys():\n",
    "    plt.plot(batch1[i]['summary']['cycle'], batch1[i]['summary']['QD'])\n",
    "_ = plt.title('Discharge Capacity (Ah) per cycle number for each cell')\n",
    "_ = plt.xlabel('Cycle Number')\n",
    "_ = plt.ylabel('Discharge Capacity (Ah)')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i, cycle in batch1[\"b1c0\"][\"cycles\"].items():\n",
    "    if (int(i)==10) | (int(i) % 100 == 0):\n",
    "        plt.plot(cycle[\"Qd\"], cycle[\"V\"], label=i)\n",
    "plt.title('Quantity of Discharge (Ah) against Voltage, Selected Cycles')\n",
    "_ = plt.ylabel('Voltage (V)')\n",
    "_ = plt.xlabel('Discharge Capacity (Ah)')\n",
    "plt.ylim(2,3.6)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "v_space = np.linspace(3.5, 2.0, 1000)\n",
    "for i, cycle in batch1[\"b1c0\"][\"cycles\"].items():\n",
    "    if (int(i)>0) & (int(i) % 100 == 0):\n",
    "        plt.plot(cycle[\"Qdlin\"], v_space, label = i)\n",
    "plt.title('Quantity of Discharge (Ah), linearly interpolated over Voltage, against Voltage, Selected Cycles')\n",
    "_ = plt.ylabel('Voltage (V)')\n",
    "_ = plt.xlabel('Discharge Capacity (Ah)')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#processed_data = pickle.load(open(cst.PROCESSED_DATA, \"rb\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#processed_data.keys()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#print_dict_keys(processed_data[\"b1c0\"]['cycles'], max_depth=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(20,10))\n",
    "#v_space = np.linspace(3.5, 2.0, 1000)\n",
    "#for i, cycle in processed_data[\"b1c0\"][\"cycles\"].items():\n",
    "#    if (int(i)>0) & (int(i) % 100 == 0):\n",
    "#        plt.plot(cycle[\"Qdlin\"], v_space, label = i)\n",
    "#plt.title('Quantity of Discharge (Ah), linearly interpolated over Voltage, Selected Cycles')\n",
    "#plt.grid()\n",
    "#plt.legend()\n",
    "#plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#del [[processed_data]]\n",
    "#gc.collect()\n",
    "#processed_data = pd.DataFrame()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing and feature selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We load features we have engineered according to the original paper from file. We used the code from the original paper to perform the feature engineering as a pre-processing step.\n",
    "The \"src/features/rebuilding_features.py\" script can be used for generating this dataset from the original data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_batches_dict = rf.load_batches_to_dict()\n",
    "features_df = rf.build_feature_df(all_batches_dict)\n",
    "\n",
    "save_csv_path = join(DATA_DIR, \"rebuild_features.csv\")\n",
    "features_df.to_csv(save_csv_path, index=False)\n",
    "print(\"Saved features to \", save_csv_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Features built as per the original paper.\n",
    "#features_df = pd.read_csv(\"../../data/external/rebuild_features.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We split the data into test and training sets. We hold out a secondary testing set for independent testing. This is done according to the methodology used in the original paper."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check how many cells of each group of cells with second letter equal to 1,2 or 3 - as per original paper.\n",
    "numBat1 = len([i for i in list(features_df.cell_key) if i[1] == \"1\"])\n",
    "numBat2 = len([i for i in list(features_df.cell_key) if i[1] == \"2\"])\n",
    "numBat3 = len([i for i in list(features_df.cell_key) if i[1] == \"3\"])\n",
    "numBat = sum((numBat1,numBat2,numBat3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_ind = np.hstack((np.arange(0,(numBat1+numBat2),2),83))\n",
    "train_ind = np.arange(1,(numBat1+numBat2-1),2)\n",
    "secondary_test_ind = np.arange(numBat-numBat3,numBat);\n",
    "\n",
    "splits = [train_ind, test_ind, secondary_test_ind]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now define feature and target columns for the baseline models."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "varmod_features = [\"variance_dQ_100_10\"]\n",
    "\n",
    "dismod_features = [\n",
    "    \"variance_dQ_100_10\",\n",
    "    \"minimum_dQ_100_10\",\n",
    "    \"skewness_dQ_100_10\",\n",
    "    \"kurtosis_dQ_100_10\",\n",
    "    \"discharge_capacity_2\",\n",
    "    \"diff_discharge_capacity_max_2\",\n",
    "]\n",
    "\n",
    "fullmod_features = [\n",
    "    \"minimum_dQ_100_10\",\n",
    "    \"variance_dQ_100_10\",\n",
    "    \"slope_lin_fit_2_100\",\n",
    "    \"intercept_lin_fit_2_100\",\n",
    "    \"discharge_capacity_2\",\n",
    "    \"mean_charge_time_2_6\",\n",
    "    \"minimum_IR_2_100\",\n",
    "    \"diff_IR_100_2\",\n",
    "]\n",
    "\n",
    "targetmod = [\"cycle_life\"]\n",
    "\n",
    "# Define feature and target columns for classifiers\n",
    "varclf_features = [\"variance_dQ_5_4\"]\n",
    "fullclf_features = [\n",
    "    \"minimum_dQ_5_4\",\n",
    "    \"variance_dQ_5_4\",\n",
    "    \"discharge_capacity_2\",\n",
    "    \"diff_IR_100_2\",\n",
    "]\n",
    "targetclf = [\"cycle_550_clf\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split data into features and response.\n",
    "def get_split(data, features, target, split):\n",
    "    X = data.iloc[split,:].loc[:,features]\n",
    "    y = data.iloc[split,:].loc[:,target]\n",
    "    return X, y\n",
    "\n",
    "# Record regression model performance.\n",
    "def eval_model(model, data, features, target, split):\n",
    "    rmse = list()\n",
    "    mpe = list()\n",
    "    rsq = list()\n",
    "    for split in splits:\n",
    "        X, y = get_split(data, features, target, split)\n",
    "        y = y.to_numpy()\n",
    "        pred = model.predict(X)\n",
    "        rmse.append(np.sqrt(mean_squared_error(pred, y)))\n",
    "        mpe.append(float(np.mean(np.abs((y - pred.reshape(-1,1))) / y * 100)))\n",
    "        rsq.append(model.score(X, y))\n",
    "    return rmse, mpe, rsq\n",
    "\n",
    "# Record classifier model performance.\n",
    "def eval_classifier(model, data, features, target, splits):\n",
    "    acc = list()    \n",
    "    for split in splits:\n",
    "        X, y = get_split(data, features, target, split)\n",
    "        pred = model.predict(X)\n",
    "        acc.append(accuracy_score(pred, y.values.ravel()))\n",
    "    return acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Variance Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train Elastic net\n",
    "x_train, y_train = get_split(features_df, varmod_features, targetmod, train_ind)\n",
    "\n",
    "alphas = np.linspace(0.0001,1,30)\n",
    "parameters = {\n",
    "    \"alpha\": alphas,\n",
    "    \"l1_ratio\": [0.001, 0.25, 0.5, 0.75, 1.]\n",
    "}\n",
    "enet = ElasticNet(random_state = 54)\n",
    "regr = GridSearchCV(enet, parameters, cv = 4)\n",
    "print(\"Elastic Net R^2: %s\" % regr.fit(x_train, y_train).score(x_train, y_train))\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "#print(\"Linear Regression: %s\" % lin_reg.fit(x_train, y_train).score(x_train, y_train))\n",
    "\n",
    "varmod_rmse, varmod_mpe, varmod_rsq = eval_model(regr, features_df, varmod_features, targetmod, splits)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regr = regr.fit(x_train, y_train)\n",
    "x_test, y_test = get_split(features_df, varmod_features, targetmod, test_ind)\n",
    "y_pred = regr.predict(x_test)\n",
    "\n",
    "plt.scatter(y_pred, y_test)\n",
    "a, b = np.polyfit(y_pred, y_test, 1)\n",
    "plt.plot(y_pred, a*y_pred+b, color='steelblue', linestyle='--', linewidth=2)\n",
    "#plt.plot(y_pred, y_test, color=\"red\")\n",
    "plt.title(\"Predictions on test set\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Discharge Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train Elastic net\n",
    "x_train, y_train = get_split(features_df, dismod_features, targetmod, train_ind)\n",
    "\n",
    "alphas = np.linspace(0.0001, 1, 30)\n",
    "parameters = {\n",
    "    \"alpha\": alphas,\n",
    "    \"l1_ratio\": [0.001, 0.25, 0.5, 0.75, 1.]\n",
    "}\n",
    "enet = ElasticNet(random_state = 54, max_iter = 1000000)\n",
    "regr = GridSearchCV(enet, parameters, cv = 4)\n",
    "print(\"Elastic Net R^2: %s\" % regr.fit(x_train, y_train).score(x_train, y_train))\n",
    "\n",
    "dismod_rmse, dismod_mpe, dismod_rsq = eval_model(regr, features_df, dismod_features, targetmod, splits)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regr = regr.fit(x_train, y_train)\n",
    "x_test, y_test = get_split(features_df, dismod_features, targetmod, test_ind)\n",
    "y_pred = regr.predict(x_test)\n",
    "\n",
    "plt.scatter(y_pred, y_test)\n",
    "a, b = np.polyfit(y_pred, y_test, 1)\n",
    "plt.plot(y_pred, a*y_pred+b, color='steelblue', linestyle='--', linewidth=2)\n",
    "#plt.plot(y_pred, y_test, color=\"red\")\n",
    "plt.title(\"Predictions on test set\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Full Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train Elastic net model\n",
    "x_train, y_train = get_split(features_df, fullmod_features, targetmod, train_ind)\n",
    "\n",
    "alphas = np.linspace(0.001, 1, 30)\n",
    "parameters = {\n",
    "    \"alpha\": alphas,\n",
    "    \"l1_ratio\": [0.001, 0.25, 0.5, 0.75, 1.]\n",
    "}\n",
    "enet = ElasticNet(random_state = 54, max_iter=1000000)\n",
    "regr = GridSearchCV(enet, parameters, cv = 4)\n",
    "print(\"Elastic Net R^2: %s\" % regr.fit(x_train, y_train).score(x_train, y_train))\n",
    "\n",
    "fullmod_rmse, fullmod_mpe, fullmod_rsq = eval_model(regr, features_df, fullmod_features, targetmod, splits)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regr = regr.fit(x_train, y_train)\n",
    "x_test, y_test = get_split(features_df, fullmod_features, targetmod, test_ind)\n",
    "y_pred = regr.predict(x_test)\n",
    "\n",
    "plt.scatter(y_pred, y_test)\n",
    "a, b = np.polyfit(y_pred, y_test, 1)\n",
    "plt.plot(y_pred, a*y_pred+b, color='steelblue', linestyle='--', linewidth=2)\n",
    "#plt.plot(y_pred, y_test, color=\"red\")\n",
    "plt.title(\"Predictions on test set\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Baseline models RMSE and MPE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reg_results = pd.DataFrame({\"Model\":[\"Variance model\", \"Discharge model\", \"Full model\"],\n",
    "              \"RMSE - Train\": [varmod_rmse[0],dismod_rmse[0],fullmod_rmse[0]],\n",
    "              \"RMSE - Primary test\": [varmod_rmse[1],dismod_rmse[1],fullmod_rmse[1]],\n",
    "              \"RMSE - Secondary test\": [varmod_rmse[2],dismod_rmse[2],fullmod_rmse[2]],\n",
    "              \"MPE - Train\": [varmod_mpe[0],dismod_mpe[0],fullmod_mpe[0]],\n",
    "              \"MPE - Primary test\": [varmod_mpe[1],dismod_mpe[1],fullmod_mpe[1]],\n",
    "              \"MPE - Secondary test\": [varmod_mpe[2],dismod_mpe[2],fullmod_mpe[2]],\n",
    "              \"RSQ - Train\": [varmod_rsq[0],dismod_rsq[0],fullmod_rsq[0]],\n",
    "              \"RSQ - Primary test\": [varmod_rsq[1],dismod_rsq[1],fullmod_rsq[1]],\n",
    "              \"RSQ - Secondary test\": [varmod_rsq[2],dismod_rsq[2],fullmod_rsq[2]]})\n",
    "\n",
    "display(reg_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The \"Discharge Model\" does not behave correctly. We need to investigate thus further.\n",
    "\n",
    "There is also too much variance between the primary and secondary test results. This is worrying. The models do not generalise well, and are possibly overfitted."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Variance Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "x_train, y_train = get_split(features_df, varclf_features, targetclf, train_ind)\n",
    "\n",
    "parameters = {\"C\": [0.01,0.1,0.5,0.75,1]}\n",
    "\n",
    "logreg = LogisticRegression(solver=\"liblinear\", random_state=54)\n",
    "clf = GridSearchCV(logreg, parameters, cv=4)\n",
    "print(\"Logreg: %s\" % clf.fit(x_train, y_train.values.ravel()).score(x_train, y_train.values.ravel()))\n",
    "\n",
    "varclf_acc = eval_classifier(clf, features_df, varclf_features, targetclf, splits)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Full Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "# Why is the full classifier worse than the variance classifier?\n",
    "x_train, y_train = get_split(features_df, fullclf_features, targetclf, train_ind)\n",
    "\n",
    "parameters = {\"C\": [0.01,0.1,0.5,0.75,1]}\n",
    "\n",
    "logreg = LogisticRegression(solver=\"liblinear\", random_state=54)\n",
    "clf = GridSearchCV(logreg, parameters, cv=4)\n",
    "print(\"Logreg: %s\" % clf.fit(x_train, y_train.values.ravel()).score(x_train, y_train.values.ravel()))\n",
    "\n",
    "fullclf_acc = eval_classifier(clf, features_df, fullclf_features, targetclf, splits)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate all classifiers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class_results = pd.DataFrame({\"Classifier\":[\"Variance classifier\", \"Full classifier\"],\n",
    "              \"Acc - Train\": [varclf_acc[0],fullclf_acc[0]],\n",
    "              \"Acc - Primary test\": [varclf_acc[1],fullclf_acc[1]],\n",
    "              \"Acc - Secondary test\": [varclf_acc[2],fullclf_acc[2]]})\n",
    "\n",
    "display(class_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We obtained roughly similar results to the original paper. Given the small datasets we expected a lot of variation when using these models.\n",
    "\n",
    "We should spend some more time to see if we can iron some of these problems out (regularisation or reducing complexity of model), but at this point we however have enough information to see how Deep Learning algorithms might perform on this problem."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Learning model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We build a deep learning model by\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "args = tm.get_args()\n",
    "model_trainer = tm.ModelTrainer(None, args)\n",
    "model_trainer.train_and_evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaling_factors = dp.load_scaling_factors()\n",
    "dataset_dir = cst.TEST_SET\n",
    "window_size = 20\n",
    "shift = 5\n",
    "stride = 1\n",
    "batch_size = 32\n",
    "\n",
    "#dataset = dp.create_dataset(dataset_dir,\n",
    "#                            window_size=window_size,\n",
    "#                            shift=shift,  # Can vary during validation\n",
    "#                            stride=stride,\n",
    "#                            batch_size=batch_size,  # Can vary during validation\n",
    "#                            cycle_length=1,  # To match original order (so no files get interleaved)\n",
    "#                            num_parallel_calls=1,  # Has to be equal or below cycle_length\n",
    "#                            shuffle=None,  # To match original order\n",
    "#                            repeat=None)\n",
    "\n",
    "dataset = dp.create_dataset(dataset_dir,\n",
    "                           window_size=20,\n",
    "                           shift=5,\n",
    "                           stride=1,\n",
    "                           batch_size=16,\n",
    "                           repeat=None)\n",
    "\n",
    "from src.models.evaluation import get_predictions_results, plot_predictions_and_errors, plot_errors_and_counts\n",
    "from src.models.clippy import Clippy, clipped_relu\n",
    "from src.models.custom_metrics_losses import mae_current_cycle, mae_remaining_cycles\n",
    "\n",
    "model_dir = \"../../data/saved_model\"\n",
    "#model = tf.keras.experimental.load_from_saved_model(model_dir, custom_objects={'clippy': Clippy(clipped_relu)})\n",
    "model = tf.keras.models.load_model(model_dir, custom_objects={\"clippy\": Clippy(clipped_relu), \"mae_current_cycle\":\n",
    "    mae_current_cycle, \"mae_remaining_cycles\": mae_remaining_cycles})\n",
    "\n",
    "results = get_predictions_results(model, dataset, scaling_factors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train Elastic net\n",
    "x_train, y_train = get_split(features_df, varmod_features, targetmod, train_ind)\n",
    "\n",
    "alphas = np.linspace(0.0001,1,30)\n",
    "parameters = {\n",
    "    \"alpha\": alphas,\n",
    "    \"l1_ratio\": [0.001, 0.25, 0.5, 0.75, 1.]\n",
    "}\n",
    "enet = ElasticNet(random_state = 54)\n",
    "regr = GridSearchCV(enet, parameters, cv = 4)\n",
    "print(\"Elastic Net R^2: %s\" % regr.fit(x_train, y_train).score(x_train, y_train))\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "#print(\"Linear Regression: %s\" % lin_reg.fit(x_train, y_train).score(x_train, y_train))\n",
    "\n",
    "varmod_rmse, varmod_mpe, varmod_rsq = eval_model(regr, features_df, varmod_features, targetmod, splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regr = regr.fit(x_train, y_train)\n",
    "x_test, y_test = get_split(features_df, varmod_features, targetmod, test_ind)\n",
    "y_pred = regr.predict(x_test)\n",
    "\n",
    "plt.scatter(y_pred, y_test)\n",
    "a, b = np.polyfit(y_pred, y_test, 1)\n",
    "plt.plot(y_pred, a*y_pred+b, color='steelblue', linestyle='--', linewidth=2)\n",
    "#plt.plot(y_pred, y_test, color=\"red\")\n",
    "plt.title(\"Predictions on test set\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Discharge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train Elastic net\n",
    "x_train, y_train = get_split(features_df, dismod_features, targetmod, train_ind)\n",
    "\n",
    "alphas = np.linspace(0.0001, 1, 30)\n",
    "parameters = {\n",
    "    \"alpha\": alphas,\n",
    "    \"l1_ratio\": [0.001, 0.25, 0.5, 0.75, 1.]\n",
    "}\n",
    "enet = ElasticNet(random_state = 54, max_iter = 1000000)\n",
    "regr = GridSearchCV(enet, parameters, cv = 4)\n",
    "print(\"Elastic Net R^2: %s\" % regr.fit(x_train, y_train).score(x_train, y_train))\n",
    "\n",
    "dismod_rmse, dismod_mpe, dismod_rsq = eval_model(regr, features_df, dismod_features, targetmod, splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regr = regr.fit(x_train, y_train)\n",
    "x_test, y_test = get_split(features_df, dismod_features, targetmod, test_ind)\n",
    "y_pred = regr.predict(x_test)\n",
    "\n",
    "plt.scatter(y_pred, y_test)\n",
    "a, b = np.polyfit(y_pred, y_test, 1)\n",
    "plt.plot(y_pred, a*y_pred+b, color='steelblue', linestyle='--', linewidth=2)\n",
    "#plt.plot(y_pred, y_test, color=\"red\")\n",
    "plt.title(\"Predictions on test set\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train Elastic net model\n",
    "x_train, y_train = get_split(features_df, fullmod_features, targetmod, train_ind)\n",
    "\n",
    "alphas = np.linspace(0.001, 1, 30)\n",
    "parameters = {\n",
    "    \"alpha\": alphas,\n",
    "    \"l1_ratio\": [0.001, 0.25, 0.5, 0.75, 1.]\n",
    "}\n",
    "enet = ElasticNet(random_state = 54, max_iter=1000000)\n",
    "regr = GridSearchCV(enet, parameters, cv = 4)\n",
    "print(\"Elastic Net R^2: %s\" % regr.fit(x_train, y_train).score(x_train, y_train))\n",
    "\n",
    "fullmod_rmse, fullmod_mpe, fullmod_rsq = eval_model(regr, features_df, fullmod_features, targetmod, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "regr = regr.fit(x_train, y_train)\n",
    "x_test, y_test = get_split(features_df, fullmod_features, targetmod, test_ind)\n",
    "y_pred = regr.predict(x_test)\n",
    "\n",
    "plt.scatter(y_pred, y_test)\n",
    "a, b = np.polyfit(y_pred, y_test, 1)\n",
    "plt.plot(y_pred, a*y_pred+b, color='steelblue', linestyle='--', linewidth=2)\n",
    "#plt.plot(y_pred, y_test, color=\"red\")\n",
    "plt.title(\"Predictions on test set\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Baseline models RMSE and MPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reg_results = pd.DataFrame({\"Model\":[\"Variance model\", \"Discharge model\", \"Full model\"],\n",
    "              \"RMSE - Train\": [varmod_rmse[0],dismod_rmse[0],fullmod_rmse[0]],\n",
    "              \"RMSE - Primary test\": [varmod_rmse[1],dismod_rmse[1],fullmod_rmse[1]],\n",
    "              \"RMSE - Secondary test\": [varmod_rmse[2],dismod_rmse[2],fullmod_rmse[2]],\n",
    "              \"MPE - Train\": [varmod_mpe[0],dismod_mpe[0],fullmod_mpe[0]],\n",
    "              \"MPE - Primary test\": [varmod_mpe[1],dismod_mpe[1],fullmod_mpe[1]],\n",
    "              \"MPE - Secondary test\": [varmod_mpe[2],dismod_mpe[2],fullmod_mpe[2]],\n",
    "              \"RSQ - Train\": [varmod_rsq[0],dismod_rsq[0],fullmod_rsq[0]],\n",
    "              \"RSQ - Primary test\": [varmod_rsq[1],dismod_rsq[1],fullmod_rsq[1]],\n",
    "              \"RSQ - Secondary test\": [varmod_rsq[2],dismod_rsq[2],fullmod_rsq[2]]})\n",
    "\n",
    "display(reg_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The \"Discharge Model\" does not behave correctly. We need to investigate thus further.\n",
    "\n",
    "There is also too much variance between the primary and secondary test results. This is worrying. The models do not generalise well, and are possibly overfitted."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Variance Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "x_train, y_train = get_split(features_df, varclf_features, targetclf, train_ind)\n",
    "\n",
    "parameters = {\"C\": [0.01,0.1,0.5,0.75,1]}\n",
    "\n",
    "logreg = LogisticRegression(solver=\"liblinear\", random_state=54)\n",
    "clf = GridSearchCV(logreg, parameters, cv=4)\n",
    "print(\"Logreg: %s\" % clf.fit(x_train, y_train.values.ravel()).score(x_train, y_train.values.ravel()))\n",
    "\n",
    "varclf_acc = eval_classifier(clf, features_df, varclf_features, targetclf, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Full Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "# Why is the full classifier worse than the variance classifier?\n",
    "x_train, y_train = get_split(features_df, fullclf_features, targetclf, train_ind)\n",
    "\n",
    "parameters = {\"C\": [0.01,0.1,0.5,0.75,1]}\n",
    "\n",
    "logreg = LogisticRegression(solver=\"liblinear\", random_state=54)\n",
    "clf = GridSearchCV(logreg, parameters, cv=4)\n",
    "print(\"Logreg: %s\" % clf.fit(x_train, y_train.values.ravel()).score(x_train, y_train.values.ravel()))\n",
    "\n",
    "fullclf_acc = eval_classifier(clf, features_df, fullclf_features, targetclf, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluate all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class_results = pd.DataFrame({\"Classifier\":[\"Variance classifier\", \"Full classifier\"],\n",
    "              \"Acc - Train\": [varclf_acc[0],fullclf_acc[0]],\n",
    "              \"Acc - Primary test\": [varclf_acc[1],fullclf_acc[1]],\n",
    "              \"Acc - Secondary test\": [varclf_acc[2],fullclf_acc[2]]})\n",
    "\n",
    "display(class_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We obtained roughly similar results to the original paper. Given the small datasets we expected a lot of variation when using these models.\n",
    "\n",
    "We should spend some more time to see if we can iron some of these problems out (regularisation or reducing complexity of model), but at this point we however have enough information to see how Deep Learning algorithms might perform on this problem."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Learning model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We build a deep learning model by\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "args = tm.get_args()\n",
    "model_trainer = tm.ModelTrainer(None, args)\n",
    "model_trainer.train_and_evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaling_factors = dp.load_scaling_factors()\n",
    "dataset_dir = cst.TEST_SET\n",
    "window_size = 20\n",
    "shift = 5\n",
    "stride = 1\n",
    "batch_size = 32\n",
    "\n",
    "#dataset = dp.create_dataset(dataset_dir,\n",
    "#                            window_size=window_size,\n",
    "#                            shift=shift,  # Can vary during validation\n",
    "#                            stride=stride,\n",
    "#                            batch_size=batch_size,  # Can vary during validation\n",
    "#                            cycle_length=1,  # To match original order (so no files get interleaved)\n",
    "#                            num_parallel_calls=1,  # Has to be equal or below cycle_length\n",
    "#                            shuffle=None,  # To match original order\n",
    "#                            repeat=None)\n",
    "\n",
    "dataset = dp.create_dataset(dataset_dir,\n",
    "                           window_size=20,\n",
    "                           shift=5,\n",
    "                           stride=1,\n",
    "                           batch_size=16,\n",
    "                           repeat=None)\n",
    "\n",
    "from src.models.evaluation import get_predictions_results, plot_predictions_and_errors, plot_errors_and_counts\n",
    "from src.models.clippy import Clippy, clipped_relu\n",
    "from src.models.custom_metrics_losses import mae_current_cycle, mae_remaining_cycles\n",
    "\n",
    "model_dir = \"../../data/saved_model\"\n",
    "#model = tf.keras.experimental.load_from_saved_model(model_dir, custom_objects={'clippy': Clippy(clipped_relu)})\n",
    "model = tf.keras.models.load_model(model_dir, custom_objects={\"clippy\": Clippy(clipped_relu), \"mae_current_cycle\":\n",
    "    mae_current_cycle, \"mae_remaining_cycles\": mae_remaining_cycles})\n",
    "\n",
    "results = get_predictions_results(model, dataset, scaling_factors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}